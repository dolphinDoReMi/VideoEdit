<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1.0" />
  <script src="https://cdn.tailwindcss.com"></script>
  <script> window.FontAwesomeConfig = { autoReplaceSvg: 'nest'};</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/js/all.min.js" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
  <style>::-webkit-scrollbar { display: none;} * { font-family: 'Inter', sans-serif; }</style>
  <script>
    tailwind.config = {
      theme: { extend: { colors: { dark: { 900:'#0a0a0a',800:'#1a1a1a',700:'#2a2a2a',600:'#3a3a3a' }}}}
    }
  </script>
</head>
<body class="bg-dark-900 text-white overflow-x-hidden">

<!-- Status Bar -->
<div id="status-bar" class="flex justify-between items-center px-4 py-2 bg-dark-800 text-xs text-gray-300">
  <div class="flex items-center space-x-1">
    <div class="w-1 h-1 bg-white rounded-full"></div>
    <div class="w-1 h-1 bg-white rounded-full"></div>
    <div class="w-1 h-1 bg-gray-600 rounded-full"></div>
    <span class="ml-2">Verizon</span>
  </div>
  <div class="font-medium">9:41</div>
  <div class="flex items-center space-x-1">
    <i class="fa-solid fa-signal text-xs"></i>
    <i class="fa-solid fa-wifi text-xs"></i>
    <div class="w-6 h-3 border border-white rounded-sm"><div class="w-4 h-2 bg-white rounded-sm m-0.5"></div></div>
  </div>
</div>

<!-- App Header -->
<div id="app-header" class="flex items-center justify-between px-6 py-4 bg-dark-800 border-b border-dark-600">
  <div class="flex items-center space-x-3">
    <button onclick="goBack()" class="w-8 h-8 bg-dark-600 rounded-full flex items-center justify-center">
      <i class="fa-solid fa-arrow-left text-gray-300 text-sm"></i>
    </button>
    <div>
      <h1 class="text-lg font-semibold text-white">Whisper Transcription</h1>
      <p class="text-xs text-gray-400">AI Speech Recognition</p>
    </div>
  </div>
  <div class="flex items-center space-x-3">
    <div class="flex items-center space-x-2">
      <div id="status-indicator" class="w-2 h-2 bg-gray-500 rounded-full"></div>
      <span id="status-text" class="text-sm text-gray-400 font-medium">Ready</span>
    </div>
  </div>
</div>

<!-- Video Selection -->
<div id="video-selection" class="px-6 py-6">
  <div class="bg-dark-700 rounded-2xl p-6 border border-dark-600 mb-6">
    <h2 class="text-xl font-semibold text-white mb-4">Video Selection</h2>
    
    <div class="flex items-center space-x-4 mb-4">
      <div class="w-16 h-12 bg-gradient-to-br from-purple-500 to-pink-500 rounded-lg flex items-center justify-center">
        <i class="fa-solid fa-video text-white text-lg"></i>
      </div>
      <div class="flex-1">
        <h3 id="video-name" class="text-white font-semibold">video_v1_long.mp4</h3>
        <p id="video-info" class="text-gray-400 text-sm">Duration: 8:54 • Size: 393 MB</p>
      </div>
      <div class="text-right">
        <p class="text-purple-400 text-sm font-medium">1080p</p>
        <p class="text-gray-400 text-xs">H.264</p>
      </div>
    </div>
    
    <div class="w-full h-40 bg-dark-600 rounded-xl flex items-center justify-center mb-4 border border-dark-500">
      <div class="text-center">
        <i class="fa-solid fa-play-circle text-4xl text-gray-400 mb-2"></i>
        <p class="text-gray-400 text-sm">Video Preview</p>
      </div>
    </div>
  </div>
</div>

<!-- Processing Configuration -->
<div id="processing-config" class="px-6 mb-6">
  <div class="bg-dark-700 rounded-2xl p-6 border border-dark-600">
    <h2 class="text-xl font-semibold text-white mb-4">Processing Configuration</h2>
    
    <div class="grid grid-cols-1 md:grid-cols-2 gap-4 mb-4">
      <div class="bg-dark-800 rounded-xl p-4 border border-dark-600">
        <p class="text-white font-medium mb-2">Model</p>
        <p class="text-sm text-gray-300">whisper-tiny.en-q5_1</p>
        <p class="text-xs text-gray-400">Fast processing, good accuracy</p>
      </div>
      <div class="bg-dark-800 rounded-xl p-4 border border-dark-600">
        <p class="text-white font-medium mb-2">Preset</p>
        <p class="text-sm text-gray-300">Single</p>
        <p class="text-xs text-gray-400">Standard processing mode</p>
      </div>
    </div>
    
    <div class="bg-dark-800 rounded-xl p-4 border border-dark-600">
      <p class="text-white font-medium mb-2">Processing Parameters</p>
      <div class="text-xs text-gray-300 space-y-1">
        <p>• Segment Duration: 30 seconds</p>
        <p>• Overlap: 1 second</p>
        <p>• Audio Format: mono@16kHz</p>
        <p>• Threads: 1</p>
      </div>
    </div>
  </div>
</div>

<!-- Processing Status -->
<div id="processing-status" class="px-6 mb-6">
  <div class="bg-dark-700 rounded-2xl p-6 border border-dark-600">
    <h2 class="text-xl font-semibold text-white mb-4">Processing Status</h2>
    
    <div id="status-display" class="space-y-4">
      <div class="flex items-center space-x-4">
        <div id="step-1" class="w-8 h-8 bg-gray-600 rounded-full flex items-center justify-center">
          <span class="text-white text-sm font-medium">1</span>
        </div>
        <div class="flex-1">
          <p class="text-white font-medium">Video Analysis</p>
          <p class="text-gray-400 text-sm">Extracting audio from video</p>
        </div>
        <div id="step-1-status" class="w-4 h-4 bg-gray-600 rounded-full"></div>
      </div>
      
      <div class="flex items-center space-x-4">
        <div id="step-2" class="w-8 h-8 bg-gray-600 rounded-full flex items-center justify-center">
          <span class="text-white text-sm font-medium">2</span>
        </div>
        <div class="flex-1">
          <p class="text-white font-medium">Speech Recognition</p>
          <p class="text-gray-400 text-sm">Processing audio with Whisper</p>
        </div>
        <div id="step-2-status" class="w-4 h-4 bg-gray-600 rounded-full"></div>
      </div>
      
      <div class="flex items-center space-x-4">
        <div id="step-3" class="w-8 h-8 bg-gray-600 rounded-full flex items-center justify-center">
          <span class="text-white text-sm font-medium">3</span>
        </div>
        <div class="flex-1">
          <p class="text-white font-medium">Export Results</p>
          <p class="text-gray-400 text-sm">Generating transcript files</p>
        </div>
        <div id="step-3-status" class="w-4 h-4 bg-gray-600 rounded-full"></div>
      </div>
    </div>
    
    <!-- Progress Bar -->
    <div class="mt-6">
      <div class="flex justify-between text-xs text-gray-400 mb-2">
        <span>Progress</span>
        <span id="progress-text">0%</span>
      </div>
      <div class="w-full bg-dark-600 rounded-full h-2">
        <div id="progress-bar" class="bg-gradient-to-r from-purple-500 to-pink-500 h-2 rounded-full transition-all duration-300" style="width: 0%"></div>
      </div>
    </div>
  </div>
</div>

<!-- Action Buttons -->
<div id="action-buttons" class="px-6 mb-6">
  <div class="grid grid-cols-1 gap-3">
    <button id="start-processing-btn"
            class="bg-gradient-to-r from-green-600 to-blue-600 hover:from-green-700 hover:to-blue-700 text-white font-semibold py-4 px-6 rounded-xl flex items-center justify-center space-x-3 transition-all active:scale-95">
      <i class="fa-solid fa-play text-xl"></i>
      <span class="text-lg">Start Transcription</span>
    </button>
    
    <button id="export-results-btn"
            class="bg-gradient-to-r from-purple-600 to-pink-600 hover:from-purple-700 hover:to-pink-700 text-white font-semibold py-4 px-6 rounded-xl flex items-center justify-center space-x-3 transition-all active:scale-95 opacity-50 cursor-not-allowed"
            disabled>
      <i class="fa-solid fa-download text-xl"></i>
      <span class="text-lg">Export Results</span>
    </button>
  </div>
</div>

<!-- Results Preview -->
<div id="results-preview" class="px-6 mb-6" style="display: none;">
  <div class="bg-dark-700 rounded-2xl p-6 border border-dark-600">
    <h2 class="text-xl font-semibold text-white mb-4">Transcription Results</h2>
    
    <div id="transcript-preview" class="bg-dark-800 rounded-xl p-4 border border-dark-600 max-h-60 overflow-y-auto">
      <p class="text-gray-400 text-sm">Transcription will appear here...</p>
    </div>
    
    <div class="mt-4 grid grid-cols-3 gap-4 text-center">
      <div>
        <p id="duration-text" class="text-white font-semibold">—</p>
        <p class="text-gray-400 text-xs">Duration</p>
      </div>
      <div>
        <p id="rtf-text" class="text-white font-semibold">—</p>
        <p class="text-gray-400 text-xs">RTF</p>
      </div>
      <div>
        <p id="segments-text" class="text-white font-semibold">—</p>
        <p class="text-gray-400 text-xs">Segments</p>
      </div>
    </div>
  </div>
</div>

<!-- Log Output -->
<div id="log-output" class="px-6 mb-20">
  <div class="bg-dark-700 rounded-2xl p-6 border border-dark-600">
    <h2 class="text-xl font-semibold text-white mb-4">Processing Log</h2>
    <div id="log-content" class="bg-dark-800 rounded-xl p-4 border border-dark-600 max-h-40 overflow-y-auto text-xs text-gray-300 font-mono">
      <p>Ready to start transcription...</p>
    </div>
  </div>
</div>

<script>
// State management
let isProcessing = false;
let currentJobId = null;
let progressInterval = null;

// DOM elements
const startBtn = document.getElementById('start-processing-btn');
const exportBtn = document.getElementById('export-results-btn');
const statusIndicator = document.getElementById('status-indicator');
const statusText = document.getElementById('status-text');
const progressBar = document.getElementById('progress-bar');
const progressText = document.getElementById('progress-text');
const logContent = document.getElementById('log-content');
const resultsPreview = document.getElementById('results-preview');

// Step elements
const step1 = document.getElementById('step-1');
const step1Status = document.getElementById('step-1-status');
const step2 = document.getElementById('step-2');
const step2Status = document.getElementById('step-2-status');
const step3 = document.getElementById('step-3');
const step3Status = document.getElementById('step-3-status');

// Logging function
function addLog(message, type = 'info') {
  const timestamp = new Date().toLocaleTimeString();
  const logEntry = document.createElement('p');
  logEntry.className = `mb-1 ${type === 'error' ? 'text-red-400' : type === 'success' ? 'text-green-400' : 'text-gray-300'}`;
  logEntry.textContent = `[${timestamp}] ${message}`;
  logContent.appendChild(logEntry);
  logContent.scrollTop = logContent.scrollHeight;
}

// Update progress
function updateProgress(percent, message) {
  progressBar.style.width = `${percent}%`;
  progressText.textContent = `${Math.round(percent)}%`;
  if (message) {
    addLog(message);
  }
}

// Update step status
function updateStepStatus(stepNumber, status) {
  const step = document.getElementById(`step-${stepNumber}`);
  const stepStatus = document.getElementById(`step-${stepNumber}-status`);
  
  if (status === 'active') {
    step.className = 'w-8 h-8 bg-blue-500 rounded-full flex items-center justify-center';
    stepStatus.className = 'w-4 h-4 bg-blue-500 rounded-full animate-pulse';
  } else if (status === 'completed') {
    step.className = 'w-8 h-8 bg-green-500 rounded-full flex items-center justify-center';
    stepStatus.className = 'w-4 h-4 bg-green-500 rounded-full';
  } else {
    step.className = 'w-8 h-8 bg-gray-600 rounded-full flex items-center justify-center';
    stepStatus.className = 'w-4 h-4 bg-gray-600 rounded-full';
  }
}

// Start processing
async function startProcessing() {
  if (isProcessing) return;
  
  isProcessing = true;
  startBtn.disabled = true;
  startBtn.className = 'bg-gray-600 text-gray-400 font-semibold py-4 px-6 rounded-xl flex items-center justify-center space-x-3 cursor-not-allowed opacity-50';
  
  statusIndicator.className = 'w-2 h-2 bg-blue-500 rounded-full animate-pulse';
  statusText.textContent = 'Processing';
  
  addLog('Starting transcription process...');
  
  try {
    // Generate job ID
    currentJobId = 'whisper_' + Date.now().toString(36);
    addLog(`Job ID: ${currentJobId}`);
    
    // Step 1: Video Analysis
    updateStepStatus(1, 'active');
    addLog('Step 1: Analyzing video file...');
    updateProgress(10, 'Extracting audio from video...');
    
    await new Promise(resolve => setTimeout(resolve, 2000));
    updateStepStatus(1, 'completed');
    updateProgress(30, 'Audio extraction completed');
    
    // Step 2: Speech Recognition
    updateStepStatus(2, 'active');
    addLog('Step 2: Processing audio with Whisper...');
    updateProgress(50, 'Running speech recognition...');
    
    // Simulate processing time based on video length (8:54 = 534 seconds)
    const processingTime = Math.min(30000, 534 * 50); // Max 30 seconds for demo
    await new Promise(resolve => setTimeout(resolve, processingTime));
    
    updateStepStatus(2, 'completed');
    updateProgress(80, 'Speech recognition completed');
    
    // Step 3: Export Results
    updateStepStatus(3, 'active');
    addLog('Step 3: Generating transcript files...');
    updateProgress(90, 'Creating export files...');
    
    await new Promise(resolve => setTimeout(resolve, 1000));
    updateStepStatus(3, 'completed');
    updateProgress(100, 'Transcription completed successfully!');
    
    // Show results
    showResults();
    
    statusIndicator.className = 'w-2 h-2 bg-green-500 rounded-full';
    statusText.textContent = 'Completed';
    
    addLog('Transcription process completed successfully!', 'success');
    
  } catch (error) {
    addLog(`Error: ${error.message}`, 'error');
    statusIndicator.className = 'w-2 h-2 bg-red-500 rounded-full';
    statusText.textContent = 'Error';
  } finally {
    isProcessing = false;
    startBtn.disabled = false;
    startBtn.className = 'bg-gradient-to-r from-green-600 to-blue-600 hover:from-green-700 hover:to-blue-700 text-white font-semibold py-4 px-6 rounded-xl flex items-center justify-center space-x-3 transition-all active:scale-95';
  }
}

// Show results
function showResults() {
  resultsPreview.style.display = 'block';
  
  // Mock results for 8:54 video
  const mockTranscript = `This is a sample transcription of the 8:54 minute video. The actual transcription would contain the full speech content extracted from the video file. This demonstrates the successful processing of a longer video file with proper audio content.

The Whisper model has successfully processed the audio and generated a complete transcript with proper timing and segmentation. The results are now ready for export in multiple formats including JSON, SRT, and TXT.`;
  
  document.getElementById('transcript-preview').innerHTML = `<p class="text-gray-300 text-sm leading-relaxed">${mockTranscript}</p>`;
  document.getElementById('duration-text').textContent = '8:54';
  document.getElementById('rtf-text').textContent = '0.45';
  document.getElementById('segments-text').textContent = '18';
  
  // Enable export button
  exportBtn.disabled = false;
  exportBtn.className = 'bg-gradient-to-r from-purple-600 to-pink-600 hover:from-purple-700 hover:to-pink-700 text-white font-semibold py-4 px-6 rounded-xl flex items-center justify-center space-x-3 transition-all active:scale-95';
}

// Export results
async function exportResults() {
  if (!currentJobId) return;
  
  addLog('Exporting transcription results...');
  
  try {
    // Simulate export process
    await new Promise(resolve => setTimeout(resolve, 1000));
    
    addLog('Export completed successfully!', 'success');
    addLog('Files saved to: /sdcard/MiraWhisper/out/');
    addLog('Formats: JSON, SRT, TXT');
    
  } catch (error) {
    addLog(`Export error: ${error.message}`, 'error');
  }
}

// Go back
function goBack() {
  if (window.AndroidWhisper && window.AndroidWhisper.goBack) {
    window.AndroidWhisper.goBack();
  } else {
    addLog('Back navigation requested');
  }
}

// Event listeners
startBtn.addEventListener('click', startProcessing);
exportBtn.addEventListener('click', exportResults);

// Initialize
addLog('Whisper transcription interface ready');
addLog('Video: video_v1_long.mp4 (8:54 duration)');
addLog('Model: whisper-tiny.en-q5_1');
addLog('Ready to start processing...');
</script>

</body>
</html>
