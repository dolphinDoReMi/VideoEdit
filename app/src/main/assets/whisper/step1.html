<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script src="https://cdn.tailwindcss.com"></script>
    <script> window.FontAwesomeConfig = { autoReplaceSvg: 'nest'};</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/js/all.min.js" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <style>::-webkit-scrollbar { display: none;}
    * { font-family: 'Inter', sans-serif; }
    </style>
    <script>
        tailwind.config = {
            theme: {
                extend: {
                    colors: {
                        dark: {
                            900: '#0a0a0a',
                            800: '#1a1a1a',
                            700: '#2a2a2a',
                            600: '#3a3a3a'
                        }
                    }
                }
            }
        }
    </script>
</head>
<body class="bg-dark-900 text-white overflow-x-hidden">

<!-- Status Bar -->
<div id="status-bar" class="flex justify-between items-center px-4 py-2 bg-dark-800 text-xs text-gray-300">
    <div class="flex items-center space-x-1">
        <div class="w-1 h-1 bg-white rounded-full"></div>
        <div class="w-1 h-1 bg-white rounded-full"></div>
        <div class="w-1 h-1 bg-gray-600 rounded-full"></div>
        <span class="ml-2">Verizon</span>
    </div>
    <div class="font-medium">9:41</div>
    <div class="flex items-center space-x-1">
        <i class="fa-solid fa-signal text-xs"></i>
        <i class="fa-solid fa-wifi text-xs"></i>
        <div class="w-6 h-3 border border-white rounded-sm">
            <div class="w-4 h-2 bg-white rounded-sm m-0.5"></div>
        </div>
    </div>
</div>

<!-- App Header -->
<div id="app-header" class="flex items-center justify-between px-6 py-4 bg-dark-800 border-b border-dark-600">
    <div class="flex items-center space-x-3">
        <button class="w-8 h-8 bg-dark-600 rounded-full flex items-center justify-center">
            <i class="fa-solid fa-arrow-left text-gray-300 text-sm"></i>
        </button>
        <div>
            <h1 class="text-lg font-semibold text-white">Whisper Transcription</h1>
            <p class="text-xs text-gray-400">AI Speech Recognition</p>
        </div>
    </div>
    <div class="flex items-center space-x-3">
        <div class="flex items-center space-x-2">
            <div id="bridge-status" class="w-2 h-2 bg-gray-500 rounded-full"></div>
            <span id="bridge-text" class="text-sm text-gray-400 font-medium">Simulation</span>
        </div>
        <button class="w-8 h-8 bg-dark-600 rounded-full flex items-center justify-center">
            <i class="fa-solid fa-ellipsis-vertical text-gray-300 text-sm"></i>
        </button>
    </div>
</div>

<!-- Audio File Selection -->
<div id="audio-selection" class="px-6 py-6">
    <div class="bg-dark-700 rounded-2xl p-4 border border-dark-600 mb-6">
        <div class="flex items-center space-x-4 mb-4">
            <div class="w-16 h-12 bg-gradient-to-br from-green-500 to-teal-500 rounded-lg flex items-center justify-center">
                <i class="fa-solid fa-microphone text-white text-lg"></i>
            </div>
            <div class="flex-1">
                <h3 id="audio-filename" class="text-white font-semibold">Select Audio File</h3>
                <p id="audio-info" class="text-gray-400 text-sm">Choose an audio file to transcribe</p>
            </div>
            <div class="text-right">
                <button id="file-select-btn" class="bg-blue-600 hover:bg-blue-700 text-white px-4 py-2 rounded-lg text-sm font-medium">
                    <i class="fa-solid fa-folder-open mr-2"></i>Select File
                </button>
            </div>
        </div>
        
        <!-- Audio Player -->
        <div id="audio-player" class="w-full h-20 bg-dark-600 rounded-xl mb-4 border border-dark-500 relative overflow-hidden" style="display: none;">
            <audio id="main-audio" class="w-full h-full" controls preload="metadata">
                Your browser does not support the audio tag.
            </audio>
        </div>
        
        <!-- Audio Metadata -->
        <div id="audio-metadata" class="grid grid-cols-3 gap-4" style="display: none;">
            <div class="text-center">
                <p id="audio-duration" class="text-white font-semibold">--</p>
                <p class="text-gray-400 text-xs">Duration</p>
            </div>
            <div class="text-center">
                <p id="audio-size" class="text-white font-semibold">--</p>
                <p class="text-gray-400 text-xs">Size</p>
            </div>
            <div class="text-center">
                <p id="audio-format" class="text-white font-semibold">--</p>
                <p class="text-gray-400 text-xs">Format</p>
            </div>
        </div>
    </div>
</div>

<!-- Whisper Configuration -->
<div id="whisper-config" class="px-6 mb-6">
    <h3 class="text-lg font-semibold text-white mb-4">Transcription Settings</h3>
    
    <div class="space-y-3">
        <!-- Preset Selection -->
        <div class="bg-dark-700 rounded-xl p-4 border border-dark-600">
            <div class="flex items-center justify-between">
                <div class="flex items-center space-x-3">
                    <div class="w-10 h-10 bg-purple-500/20 rounded-lg flex items-center justify-center">
                        <i class="fa-solid fa-cog text-purple-400"></i>
                    </div>
                    <div>
                        <h4 class="text-white font-medium">Preset</h4>
                        <p class="text-gray-400 text-sm">Choose transcription quality</p>
                    </div>
                </div>
                <select id="preset-select" class="bg-dark-600 text-white px-3 py-2 rounded-lg border border-dark-500">
                    <option value="single">Single (Fast)</option>
                    <option value="accuracy">Accuracy (Slow)</option>
                </select>
            </div>
        </div>
        
        <!-- Model Selection -->
        <div class="bg-dark-700 rounded-xl p-4 border border-dark-600">
            <div class="flex items-center justify-between">
                <div class="flex items-center space-x-3">
                    <div class="w-10 h-10 bg-blue-500/20 rounded-lg flex items-center justify-center">
                        <i class="fa-solid fa-brain text-blue-400"></i>
                    </div>
                    <div>
                        <h4 class="text-white font-medium">Model</h4>
                        <p class="text-gray-400 text-sm">Whisper model size</p>
                    </div>
                </div>
                <select id="model-select" class="bg-dark-600 text-white px-3 py-2 rounded-lg border border-dark-500">
                    <option value="whisper-tiny.en-q5_1.bin">Tiny (39MB)</option>
                    <option value="whisper-base.en-q5_1.bin">Base (142MB)</option>
                    <option value="whisper-small.en-q5_1.bin">Small (244MB)</option>
                </select>
            </div>
        </div>
        
        <!-- Advanced Settings -->
        <div class="bg-dark-700 rounded-xl p-4 border border-dark-600">
            <div class="flex items-center justify-between mb-3">
                <div class="flex items-center space-x-3">
                    <div class="w-10 h-10 bg-green-500/20 rounded-lg flex items-center justify-center">
                        <i class="fa-solid fa-sliders text-green-400"></i>
                    </div>
                    <div>
                        <h4 class="text-white font-medium">Advanced Settings</h4>
                        <p class="text-gray-400 text-sm">Fine-tune transcription parameters</p>
                    </div>
                </div>
                <button id="advanced-toggle" class="text-gray-400 text-sm">
                    <i class="fa-solid fa-chevron-down"></i>
                </button>
            </div>
            
            <div id="advanced-settings" class="space-y-3" style="display: none;">
                <div class="grid grid-cols-2 gap-3">
                    <div>
                        <label class="text-gray-400 text-sm">Segment Length (ms)</label>
                        <input id="segment-ms" type="number" value="30000" class="w-full bg-dark-600 text-white px-3 py-2 rounded-lg border border-dark-500 mt-1">
                    </div>
                    <div>
                        <label class="text-gray-400 text-sm">Overlap (ms)</label>
                        <input id="overlap-ms" type="number" value="1000" class="w-full bg-dark-600 text-white px-3 py-2 rounded-lg border border-dark-500 mt-1">
                    </div>
                </div>
                
                <div class="grid grid-cols-2 gap-3">
                    <div>
                        <label class="text-gray-400 text-sm">Temperature</label>
                        <input id="temperature" type="number" value="0.0" step="0.1" min="0" max="1" class="w-full bg-dark-600 text-white px-3 py-2 rounded-lg border border-dark-500 mt-1">
                    </div>
                    <div>
                        <label class="text-gray-400 text-sm">Beam Size</label>
                        <input id="beam-size" type="number" value="1" min="1" max="5" class="w-full bg-dark-600 text-white px-3 py-2 rounded-lg border border-dark-500 mt-1">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<!-- Transcription Status -->
<div id="transcription-status" class="px-6 mb-6" style="display: none;">
    <div class="bg-gradient-to-r from-dark-700 to-dark-600 rounded-2xl p-6 border border-dark-600">
        <div class="flex items-center justify-between mb-4">
            <h2 class="text-xl font-semibold text-white">Transcription Progress</h2>
            <div class="flex items-center space-x-2">
                <div id="transcription-indicator" class="w-2 h-2 bg-blue-500 rounded-full animate-pulse"></div>
                <span id="transcription-status-text" class="text-sm text-blue-400 font-medium">Processing</span>
            </div>
        </div>
        
        <!-- Current Phase Display -->
        <div id="current-phase" class="bg-dark-800 rounded-xl p-4 mb-6 border border-dark-600">
            <div class="flex items-center space-x-4">
                <div class="w-12 h-12 bg-blue-500/20 rounded-xl flex items-center justify-center">
                    <div id="phase-icon" class="w-6 h-6 border-2 border-blue-500 border-t-transparent rounded-full animate-spin"></div>
                </div>
                <div class="flex-1">
                    <h3 id="phase-title" class="text-white font-semibold text-lg">Initializing...</h3>
                    <p id="phase-description" class="text-gray-400 text-sm">Preparing audio for transcription</p>
                </div>
                <div class="text-right">
                    <p id="phase-progress" class="text-blue-400 font-semibold">0%</p>
                    <p class="text-gray-400 text-xs">Complete</p>
                </div>
            </div>
            
            <!-- Progress Bar -->
            <div class="w-full bg-dark-600 rounded-full h-2 mt-4">
                <div id="phase-progress-bar" class="bg-gradient-to-r from-blue-500 to-purple-500 h-2 rounded-full transition-all duration-500" style="width: 0%"></div>
            </div>
        </div>
        
        <!-- Estimated Time -->
        <div class="flex items-center justify-between text-sm">
            <div class="flex items-center space-x-2">
                <i class="fa-solid fa-clock text-purple-400"></i>
                <span class="text-gray-400">Estimated time remaining:</span>
            </div>
            <span id="time-remaining" class="text-white font-medium">Calculating...</span>
        </div>
    </div>
</div>

<!-- Results Section -->
<div id="results-section" class="px-6 mb-6" style="display: none;">
    <h3 class="text-lg font-semibold text-white mb-4">Transcription Results</h3>
    
    <div class="space-y-4">
        <!-- RTF Display -->
        <div class="bg-dark-700 rounded-xl p-4 border border-dark-600">
            <div class="flex items-center justify-between">
                <div class="flex items-center space-x-3">
                    <div class="w-10 h-10 bg-green-500/20 rounded-lg flex items-center justify-center">
                        <i class="fa-solid fa-tachometer-alt text-green-400"></i>
                    </div>
                    <div>
                        <h4 class="text-white font-medium">Real-Time Factor</h4>
                        <p class="text-gray-400 text-sm">Processing speed indicator</p>
                    </div>
                </div>
                <div class="text-right">
                    <p id="rtf-value" class="text-green-400 font-semibold text-lg">--</p>
                    <p class="text-gray-400 text-xs">RTF</p>
                </div>
            </div>
        </div>
        
        <!-- Transcript Display -->
        <div class="bg-dark-700 rounded-xl p-4 border border-dark-600">
            <div class="flex items-center justify-between mb-3">
                <h4 class="text-white font-medium">Transcript</h4>
                <div class="flex space-x-2">
                    <button id="copy-transcript" class="text-blue-400 text-sm font-medium">
                        <i class="fa-solid fa-copy mr-1"></i>Copy
                    </button>
                    <button id="download-transcript" class="text-green-400 text-sm font-medium">
                        <i class="fa-solid fa-download mr-1"></i>Download
                    </button>
                </div>
            </div>
            <div id="transcript-text" class="text-gray-300 text-sm leading-relaxed max-h-40 overflow-y-auto">
                <!-- Transcript will be populated here -->
            </div>
        </div>
        
        <!-- Segments Display -->
        <div class="bg-dark-700 rounded-xl p-4 border border-dark-600">
            <div class="flex items-center justify-between mb-3">
                <h4 class="text-white font-medium">Segments</h4>
                <button id="download-segments" class="text-purple-400 text-sm font-medium">
                    <i class="fa-solid fa-download mr-1"></i>Download SRT
                </button>
            </div>
            <div id="segments-list" class="space-y-2 max-h-40 overflow-y-auto">
                <!-- Segments will be populated here -->
            </div>
        </div>
        
        <!-- Verification -->
        <div class="bg-dark-700 rounded-xl p-4 border border-dark-600">
            <div class="flex items-center justify-between">
                <div class="flex items-center space-x-3">
                    <div class="w-10 h-10 bg-yellow-500/20 rounded-lg flex items-center justify-center">
                        <i class="fa-solid fa-check-circle text-yellow-400"></i>
                    </div>
                    <div>
                        <h4 class="text-white font-medium">Verification</h4>
                        <p class="text-gray-400 text-sm">Re-run & Compare for deterministic results</p>
                    </div>
                </div>
                <button id="verify-btn" class="bg-yellow-600 hover:bg-yellow-700 text-white px-4 py-2 rounded-lg text-sm font-medium">
                    <i class="fa-solid fa-redo mr-2"></i>Re-run & Compare
                </button>
            </div>
        </div>
    </div>
</div>

<!-- Control Actions -->
<div id="control-actions" class="px-6 mb-6">
    <div class="grid grid-cols-2 gap-3">
        <button id="run-transcription" class="bg-green-600 hover:bg-green-700 text-white font-semibold py-3 px-4 rounded-xl flex items-center justify-center space-x-2 transition-colors">
            <i class="fa-solid fa-play"></i>
            <span>Run Transcription</span>
        </button>
        
        <button id="cancel-transcription" class="bg-red-600 hover:bg-red-700 text-white font-semibold py-3 px-4 rounded-xl flex items-center justify-center space-x-2 transition-colors" style="display: none;">
            <i class="fa-solid fa-stop"></i>
            <span>Cancel</span>
        </button>
    </div>
</div>

<!-- Processing Log -->
<div id="processing-log" class="px-6 mb-20">
    <h3 class="text-lg font-semibold text-white mb-4">Processing Log</h3>
    
    <div class="bg-dark-700 rounded-xl p-4 border border-dark-600">
        <div id="log-entries" class="space-y-3 max-h-40 overflow-y-auto">
            <div class="flex items-start space-x-3">
                <div class="w-2 h-2 bg-green-500 rounded-full mt-2"></div>
                <div class="flex-1">
                    <p class="text-white text-sm">Whisper UI initialized</p>
                    <p class="text-gray-400 text-xs" id="init-time">--:--:--</p>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
// ---------- Bridge (BroadcastChannel/window.postMessage) ----------
let bridgeChannel = null;
let bridgeEnabled = false;
let bridgeTimeout = null;
let currentRunId = null;

// Check for bridge enablement
function checkBridgeEnabled() {
    const urlParams = new URLSearchParams(window.location.search);
    const bridgeParam = urlParams.get('bridge');
    const bridgeStorage = localStorage.getItem('whisper.bridge');
    
    // Enable bridge by default in dev builds (localhost or file://)
    const isDevBuild = window.location.hostname === 'localhost' || 
                       window.location.protocol === 'file:' ||
                       window.location.hostname === '127.0.0.1';
    
    bridgeEnabled = bridgeParam === '1' || bridgeStorage === '1' || (isDevBuild && bridgeParam !== '0');
    
    if (bridgeEnabled) {
        console.log('Whisper bridge enabled');
        document.getElementById('bridge-status').className = 'w-2 h-2 bg-green-500 rounded-full';
        document.getElementById('bridge-text').textContent = 'Bridge';
        document.getElementById('bridge-text').className = 'text-sm text-green-400 font-medium';
        
        // Initialize BroadcastChannel
        if (typeof BroadcastChannel !== 'undefined') {
            bridgeChannel = new BroadcastChannel('whisper-ui');
            bridgeChannel.onmessage = handleBridgeMessage;
            console.log('BroadcastChannel initialized');
        } else {
            // Fallback to window.postMessage
            window.addEventListener('message', handleBridgeMessage);
            console.log('Using window.postMessage fallback');
        }
    } else {
        console.log('Whisper bridge disabled - using simulation');
    }
}

// Handle messages from host
function handleBridgeMessage(event) {
    const data = event.data || event;
    console.log('Bridge received:', data);
    
    switch (data.type) {
        case 'whisper.ack':
            console.log('Host acknowledged run');
            clearTimeout(bridgeTimeout);
            break;
            
        case 'whisper.progress':
            updateTranscriptionProgress(data.phase, data.pct, data.msg);
            break;
            
        case 'whisper.done':
            applyArtifactsFromDone(data);
            break;
            
        case 'whisper.error':
            handleTranscriptionError(data.error);
            break;
    }
}

// Send message to host
function sendToHost(message) {
    if (!bridgeEnabled) return;
    
    console.log('Sending to host:', message);
    
    if (bridgeChannel) {
        bridgeChannel.postMessage(message);
    } else {
        // Fallback for window.postMessage
        window.postMessage(message, '*');
    }
}

// Apply results from host
function applyArtifactsFromDone(payload) {
    console.log('Applying artifacts from host:', payload);
    
    // Update UI with results
    if (payload.transcript) {
        document.getElementById('transcript-text').textContent = payload.transcript.text;
        
        // Update segments
        const segmentsList = document.getElementById('segments-list');
        segmentsList.innerHTML = '';
        payload.transcript.segments.forEach(segment => {
            const segmentDiv = document.createElement('div');
            segmentDiv.className = 'flex items-center space-x-3 p-2 bg-dark-600 rounded-lg';
            segmentDiv.innerHTML = `
                <span class="text-blue-400 text-xs font-mono w-16">${formatTime(segment.start_ms)}</span>
                <span class="text-white text-sm flex-1">${segment.text}</span>
            `;
            segmentsList.appendChild(segmentDiv);
        });
    }
    
    // Update RTF
    if (payload.sidecar) {
        document.getElementById('rtf-value').textContent = payload.sidecar.rtf.toFixed(2);
    }
    
    // Show results section
    document.getElementById('results-section').style.display = 'block';
    document.getElementById('transcription-status').style.display = 'none';
    document.getElementById('run-transcription').style.display = 'flex';
    document.getElementById('cancel-transcription').style.display = 'none';
    
    addLogEntry('Transcription completed successfully');
}

// ---------- Main Transcription Logic ----------
let selectedFile = null;
let isTranscribing = false;

// File selection
document.getElementById('file-select-btn').addEventListener('click', function() {
    const input = document.createElement('input');
    input.type = 'file';
    input.accept = 'audio/*,video/*';
    input.onchange = function(e) {
        const file = e.target.files[0];
        if (file) {
            selectedFile = file;
            updateFileInfo(file);
            addLogEntry(`Selected file: ${file.name}`);
        }
    };
    input.click();
});

function updateFileInfo(file) {
    document.getElementById('audio-filename').textContent = file.name;
    document.getElementById('audio-info').textContent = `${formatFileSize(file.size)} • ${file.type}`;
    
    // Show audio player
    const audioPlayer = document.getElementById('audio-player');
    const audio = document.getElementById('main-audio');
    audio.src = URL.createObjectURL(file);
    audioPlayer.style.display = 'block';
    
    // Show metadata
    document.getElementById('audio-metadata').style.display = 'grid';
    
    // Update metadata when audio loads
    audio.onloadedmetadata = function() {
        document.getElementById('audio-duration').textContent = formatTime(audio.duration * 1000);
        document.getElementById('audio-size').textContent = formatFileSize(file.size);
        document.getElementById('audio-format').textContent = file.type.split('/')[1].toUpperCase();
    };
}

// Advanced settings toggle
document.getElementById('advanced-toggle').addEventListener('click', function() {
    const settings = document.getElementById('advanced-settings');
    const icon = this.querySelector('i');
    
    if (settings.style.display === 'none') {
        settings.style.display = 'block';
        icon.className = 'fa-solid fa-chevron-up';
    } else {
        settings.style.display = 'none';
        icon.className = 'fa-solid fa-chevron-down';
    }
});

// Run transcription
document.getElementById('run-transcription').addEventListener('click', function() {
    if (!selectedFile) {
        alert('Please select an audio file first');
        return;
    }
    
    if (bridgeEnabled) {
        runStepsWithBridge();
    } else {
        runStepsSimulation();
    }
});

// Bridge-enabled transcription
function runStepsWithBridge() {
    console.log('Running transcription with bridge');
    
    const config = {
        preset: document.getElementById('preset-select').value,
        segmentMs: parseInt(document.getElementById('segment-ms').value),
        overlapMs: parseInt(document.getElementById('overlap-ms').value),
        timestamp_policy: 'EXTRACTOR_PTS',
        resampler: 'LINEAR',
        decoder: 'aac_hw_first',
        model_file: document.getElementById('model-select').value,
        model_sha256: 'placeholder_sha256',
        threads: 'profile',
        greedy: true,
        beam: parseInt(document.getElementById('beam-size').value),
        temperature: parseFloat(document.getElementById('temperature').value)
    };
    
    const runEvent = {
        type: 'whisper.run',
        config: config,
        config_sha256: 'placeholder_config_sha256',
        input: {
            name: selectedFile.name,
            size: selectedFile.size,
            type: selectedFile.type
        },
        audio_sha256_hint: 'placeholder_audio_sha256'
    };
    
    currentRunId = Date.now();
    sendToHost(runEvent);
    
    // Set timeout for fallback
    bridgeTimeout = setTimeout(() => {
        console.log('No host response, falling back to simulation');
        runStepsSimulation();
    }, 800);
    
    // Show transcription status
    showTranscriptionStatus();
}

// Simulation transcription (fallback)
function runStepsSimulation() {
    console.log('Running transcription simulation');
    showTranscriptionStatus();
    
    const phases = [
        { phase: 'decode', pct: 15, msg: 'Decoding audio...', duration: 2000 },
        { phase: 'segment', pct: 35, msg: 'Deterministic segmentation...', duration: 1500 },
        { phase: 'preprocess', pct: 55, msg: 'Preprocessing audio...', duration: 1000 },
        { phase: 'inference', pct: 85, msg: 'Whisper inference...', duration: 3000 },
        { phase: 'serialize', pct: 100, msg: 'Serializing results...', duration: 500 }
    ];
    
    let currentPhase = 0;
    
    function nextPhase() {
        if (currentPhase < phases.length) {
            const phase = phases[currentPhase];
            updateTranscriptionProgress(phase.phase, phase.pct, phase.msg);
            
            if (currentPhase === phases.length - 1) {
                // Complete with simulated results
                setTimeout(() => {
                    applyArtifactsFromDone({
                        input_name: selectedFile.name,
                        transcript_sha256: 'simulated_sha256',
                        sidecar: {
                            model_file: document.getElementById('model-select').value,
                            model_sha256: 'simulated_model_sha256',
                            audio_sha256: 'simulated_audio_sha256',
                            config_sha256: 'simulated_config_sha256',
                            preset: document.getElementById('preset-select').value,
                            segment_ms: parseInt(document.getElementById('segment-ms').value),
                            overlap_ms: parseInt(document.getElementById('overlap-ms').value),
                            timestamp_policy: 'EXTRACTOR_PTS',
                            resampler: 'LINEAR',
                            decoder: 'aac_hw_first',
                            threads: 'profile',
                            greedy: true,
                            beam: parseInt(document.getElementById('beam-size').value),
                            temperature: parseFloat(document.getElementById('temperature').value),
                            infer_ms: 4200,
                            audio_ms: 6000,
                            rtf: 0.7,
                            created_at: new Date().toISOString()
                        },
                        transcript: {
                            segments: [
                                { i: 0, start_ms: 0, end_ms: 29000, text: 'Hello world, this is a test transcription.' },
                                { i: 1, start_ms: 30000, end_ms: 59000, text: 'The Whisper model is working correctly.' }
                            ],
                            text: 'Hello world, this is a test transcription. The Whisper model is working correctly.'
                        }
                    });
                }, phase.duration);
            } else {
                setTimeout(nextPhase, phase.duration);
            }
            currentPhase++;
        }
    }
    
    nextPhase();
}

function showTranscriptionStatus() {
    document.getElementById('transcription-status').style.display = 'block';
    document.getElementById('run-transcription').style.display = 'none';
    document.getElementById('cancel-transcription').style.display = 'flex';
    isTranscribing = true;
    
    addLogEntry('Starting transcription...');
}

function updateTranscriptionProgress(phase, pct, msg) {
    document.getElementById('phase-title').textContent = msg || `Processing ${phase}...`;
    document.getElementById('phase-description').textContent = getPhaseDescription(phase);
    document.getElementById('phase-progress').textContent = pct + '%';
    document.getElementById('phase-progress-bar').style.width = pct + '%';
    
    // Update phase icon
    const icon = document.getElementById('phase-icon');
    icon.className = 'w-6 h-6 border-2 border-blue-500 border-t-transparent rounded-full animate-spin';
    
    addLogEntry(`${phase}: ${pct}% - ${msg || 'Processing...'}`);
}

function getPhaseDescription(phase) {
    const descriptions = {
        'decode': 'Extracting audio from file',
        'segment': 'Dividing audio into segments',
        'preprocess': 'Preparing audio for inference',
        'inference': 'Running Whisper model',
        'serialize': 'Formatting results'
    };
    return descriptions[phase] || 'Processing audio';
}

function handleTranscriptionError(error) {
    console.error('Transcription error:', error);
    addLogEntry(`Error: ${error}`);
    
    // Reset UI
    document.getElementById('transcription-status').style.display = 'none';
    document.getElementById('run-transcription').style.display = 'flex';
    document.getElementById('cancel-transcription').style.display = 'none';
    isTranscribing = false;
}

// Cancel transcription
document.getElementById('cancel-transcription').addEventListener('click', function() {
    if (confirm('Are you sure you want to cancel the transcription?')) {
        isTranscribing = false;
        clearTimeout(bridgeTimeout);
        
        document.getElementById('transcription-status').style.display = 'none';
        document.getElementById('run-transcription').style.display = 'flex';
        document.getElementById('cancel-transcription').style.display = 'none';
        
        addLogEntry('Transcription cancelled by user');
    }
});

// Utility functions
function formatTime(ms) {
    const seconds = Math.floor(ms / 1000);
    const minutes = Math.floor(seconds / 60);
    const remainingSeconds = seconds % 60;
    return `${minutes}:${remainingSeconds.toString().padStart(2, '0')}`;
}

function formatFileSize(bytes) {
    if (bytes === 0) return '0 Bytes';
    const k = 1024;
    const sizes = ['Bytes', 'KB', 'MB', 'GB'];
    const i = Math.floor(Math.log(bytes) / Math.log(k));
    return parseFloat((bytes / Math.pow(k, i)).toFixed(2)) + ' ' + sizes[i];
}

function addLogEntry(message) {
    const logEntries = document.getElementById('log-entries');
    const time = new Date().toLocaleTimeString();
    
    const entry = document.createElement('div');
    entry.className = 'flex items-start space-x-3';
    entry.innerHTML = `
        <div class="w-2 h-2 bg-blue-500 rounded-full mt-2"></div>
        <div class="flex-1">
            <p class="text-white text-sm">${message}</p>
            <p class="text-gray-400 text-xs">${time}</p>
        </div>
    `;
    
    logEntries.appendChild(entry);
    logEntries.scrollTop = logEntries.scrollHeight;
}

// Copy transcript
document.getElementById('copy-transcript').addEventListener('click', function() {
    const transcript = document.getElementById('transcript-text').textContent;
    navigator.clipboard.writeText(transcript).then(() => {
        addLogEntry('Transcript copied to clipboard');
    });
});

// Download transcript
document.getElementById('download-transcript').addEventListener('click', function() {
    const transcript = document.getElementById('transcript-text').textContent;
    const blob = new Blob([transcript], { type: 'text/plain' });
    const url = URL.createObjectURL(blob);
    const a = document.createElement('a');
    a.href = url;
    a.download = 'transcript.txt';
    a.click();
    URL.revokeObjectURL(url);
    addLogEntry('Transcript downloaded');
});

// Download segments as SRT
document.getElementById('download-segments').addEventListener('click', function() {
    const segments = document.querySelectorAll('#segments-list > div');
    let srtContent = '';
    
    segments.forEach((segment, index) => {
        const timeText = segment.querySelector('.text-blue-400').textContent;
        const text = segment.querySelector('.text-white').textContent;
        
        srtContent += `${index + 1}\n`;
        srtContent += `${timeText} --> ${timeText}\n`;
        srtContent += `${text}\n\n`;
    });
    
    const blob = new Blob([srtContent], { type: 'text/plain' });
    const url = URL.createObjectURL(blob);
    const a = document.createElement('a');
    a.href = url;
    a.download = 'transcript.srt';
    a.click();
    URL.revokeObjectURL(url);
    addLogEntry('SRT file downloaded');
});

// Verify button
document.getElementById('verify-btn').addEventListener('click', function() {
    addLogEntry('Starting verification run...');
    if (bridgeEnabled) {
        runStepsWithBridge();
    } else {
        runStepsSimulation();
    }
});

// Initialize
document.addEventListener('DOMContentLoaded', function() {
    checkBridgeEnabled();
    document.getElementById('init-time').textContent = new Date().toLocaleTimeString();
});

</script>

</body>
</html>
